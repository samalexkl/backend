hydra:
  searchpath:
    - file://mdlm/configs
  run:
    dir: ./outputs/${fk_steering.potential_type}_${fk_steering.k_particles}_${fk_steering.lmbda}_${fk_steering.reward_fn}_${fk_steering.reward_label}_${fk_steering.resample_frequency}_${fk_steering.num_x0_samples}/${now:%Y.%m.%d}/${now:%H%M%S}
  job:
    chdir: true

defaults:
  - config  # Refers to 'config.yaml' inside 'mdlm/configs'
  - _self_

sampling:
  prompt_file: null # prompt path, e.g. evaluation/pplm_discrim_prompts_orig.jsonl
  predictor: ddpm # ddpm_cache not supported right now

fk_steering:
  potential_type: 'diff' # see fkd_class.py for options
  k_particles: 4
  lmbda: 10.0
  reward_fn: 'toxicity' # see reward_functions.py for options # WARNING: toxicity guidance leads to potentially harmful outputs
  reward_label: 'positive'
  reward_trim_length: 1024 # Number of tokens to consider for reward computation, if < seq leq considers first reward_trim_length tokens
  resample_frequency: 20 # -1 for no resampling
  num_x0_samples: 4
  resample_start_step: -1